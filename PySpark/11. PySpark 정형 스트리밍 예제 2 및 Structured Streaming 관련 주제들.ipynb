{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8068a7a2",
   "metadata": {},
   "source": [
    "### Structured Streaming File Source 프로그램 구조\n",
    "1. 디렉토리로부터 스트리밍 데이터 파일을 읽어 DataFrame을 생성\n",
    "- Streaming DataFrame이라고 함\n",
    "- static DataFrame: Streaming DataFrame이 아닌 일반 DataFrame\n",
    "2. DataFrame 작업 실행\n",
    "- Static DataFrame의 자체 methods 실행과 동일\n",
    "3. 결과 DataFrame의 산출 쿼리를 실행\n",
    "4. 스트리밍 작업 대기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b85cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6aef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4f6046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef81155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aec83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a0c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession \\\n",
    ".builder \\\n",
    ".master(\"local\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2003163",
   "metadata": {},
   "outputs": [],
   "source": [
    "dessertMenuDF = spark.read \\\n",
    ".option(\"inferSchema\", \"true\") \\\n",
    ".option(\"header\", \"true\") \\\n",
    ".format(\"csv\") \\\n",
    ".load(\"C:/spark/data/dessert-menu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74ab034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-----+----+\n",
      "|menuId|           name|price|kcal|\n",
      "+------+---------------+-----+----+\n",
      "|   D-0|  초콜릿 파르페| 4900| 420|\n",
      "|   D-1|    푸딩 파르페| 5300| 380|\n",
      "|   D-2|    딸기 파르페| 5200| 320|\n",
      "|   D-3|       판나코타| 4200| 283|\n",
      "|   D-4|      치즈 무스| 5800| 288|\n",
      "|   D-5|       아포가토| 3000| 248|\n",
      "|   D-6|       티라미스| 6000| 251|\n",
      "|   D-7|    녹차 파르페| 4500| 380|\n",
      "|   D-8|  바닐라 젤라또| 3600| 131|\n",
      "|   D-9|  카라멜 팬케익| 3900| 440|\n",
      "|  D-10|    크림 안미츠| 5000| 250|\n",
      "|  D-11|  고구마 파르페| 6500| 650|\n",
      "|  D-12|      녹차 빙수| 3800| 320|\n",
      "|  D-13|  초코 크레이프| 3700| 300|\n",
      "|  D-14|바나나 크레이프| 3300| 220|\n",
      "|  D-15|  커스터드 푸딩| 2000| 120|\n",
      "|  D-16|    초코 토르테| 3300| 220|\n",
      "|  D-17|    치즈 수플레| 2200| 160|\n",
      "|  D-18|    호박 타르트| 3400| 230|\n",
      "|  D-19|      캬라멜 롤| 3700| 230|\n",
      "+------+---------------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dessertMenuDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e45d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6608134",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderSchema = StructType([ StructField(\"orderId\", StringType()), \\\n",
    "                           StructField(\"menuId\", StringType()), \\\n",
    "                           StructField(\"number\", IntegerType()) \\\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "851f0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "dessertOrderDF = spark.readStream \\\n",
    ".schema(orderSchema) \\\n",
    ".format(\"csv\") \\\n",
    ".load(\"C:/spark/streamingIn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29be6c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderId: string (nullable = true)\n",
      " |-- menuId: string (nullable = true)\n",
      " |-- number: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dessertOrderDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07275240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주문별 금액\n",
    "\n",
    "orderTotal = dessertOrderDF.join(dessertMenuDF, dessertOrderDF.menuId == dessertMenuDF.menuId) \\\n",
    ".groupBy(dessertOrderDF.orderId) \\\n",
    ".agg(sum(dessertOrderDF.number * dessertMenuDF.price).alias('orderTotal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bfad13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderQuery = orderTotal.writeStream \\\n",
    ".format(\"console\") \\\n",
    ".outputMode(\"complete\") \\\n",
    ".start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10a08e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.streaming.StreamingQuery"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(orderQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderQuery.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba3006",
   "metadata": {},
   "source": [
    "### Structured Streaming File Source\n",
    "- 디렉토리에 있는 파일들을 실행\n",
    "- 새로운 파일이 추가되면 스트리밍 작업을 실행\n",
    "    - 기존 파일을 포함하여 디렉토리내에 있는 모든 파일을 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b469f88",
   "metadata": {},
   "source": [
    "### Structured Streaming 관련 주제들\n",
    "- withWatermark(\"event time\",\"30 minutes\")\n",
    "    - 파일을 읽을 때, 분산환경에서 읽어들이기 때문에 읽은 파일을 제대로 전달받지 못할 가능성이 있음.\n",
    "        - 얼마나 오래 기다릴 것인가르 지정하는 method임.\n",
    "        - Structured streaming은 .withWatermark에 지정한 시간이 지날 때까지 기다렸다가, 결과 처리를 종료함.\n",
    "\n",
    "- dropDuplicates([\"User\", \"event time\"])\n",
    "    - 분산 환경에서는 데이터를 복사하여 다른 경로로 전달할 수 있음\n",
    "        - 데이터가 중복 전달될 수 있음\n",
    "    - 인자로 지정한 컬럼들의 값들이 같은 레코드들은 중복된 것으로 간주하여 중복 제거하여 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8808b857",
   "metadata": {},
   "source": [
    "### Windowing: Event-Time\n",
    "-Processing Time과 Event Time\n",
    "    - Processing Time: 스트림 데이터 처리 프로그램이 실제로 데이터를 수신한 시각\n",
    "    - Event Time: 데이터가 발생한 시각\n",
    "- Dstream에서 스트림 데이터 처리 기준\n",
    "    - Processing Time\n",
    "    - 따라서 Window Operation이 가능\n",
    "- StructuredStreaming에서 스트림 데이터 처리 기준\n",
    "    - Event Time\n",
    "    - 각 데이터가 Event time을 나타내는 필드(컬럼)을 가지고 있는 경우 (예:timestamp) 이를 기준으로 groupBy 연산을 통하여 Window Operation을 처리할 수 있음\n",
    "    \n",
    "wordCountQuery = wordCount.groupBy(window(wordCount.timestamp, \"10 minutes\"), wordCount.word).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee8264a",
   "metadata": {},
   "source": [
    "### checkpointLocation 디렉토리의 정보\n",
    "- 실행된 파일들에 대한 이력정보가 저장되어 있음.\n",
    "    - 프로그램 개발 중 입력 디렉토리에 있는 파일들을 지우거나 하면, 해당 파일이 없어진 것을 checkpointLocation에 저장된 정보를 사용하여 체크함\n",
    "    - 따라서, 개발 중에는 사용하지 않는 것이 좋음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65533f",
   "metadata": {},
   "source": [
    "### Structured Streaming 프로그램 개발 시 고려사항\n",
    "- 입력 파일의 생성 시간이 역순으로 디렉토리에 저장될 경우 ,해당 시간차가 클 경우(즉, 늦게 발생한 파일이 먼저 도착하고, 일찍 발생한 파일이 너무 늦게 도착하면), 늦게 도착한 파일이 처리되지 않음 -> .withWatermark() 참조\n",
    "- Master 지정\n",
    "    - loca(*)로 master 지정 -> 속도 개선에 도움이 됨.\n",
    "        - SparkSession을 생성할 때, master 지정\n",
    "        - .master(\"local\") -> .master(\"local[*]\")로 지정"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
